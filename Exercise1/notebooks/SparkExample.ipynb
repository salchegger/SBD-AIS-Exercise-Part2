{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99874275",
   "metadata": {},
   "source": [
    "### Exercise 3 : Run with Spark (inside Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4537d9-52a8-43de-9411-e1b20e55fc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading people_big from PostgreSQL ===\n",
      "Rows loaded: 1000000\n",
      "Load time: 9.36 seconds\n",
      "\n",
      "=== Query (a): AVG salary per department ===\n",
      "+------------------+----------+\n",
      "|department        |avg_salary|\n",
      "+------------------+----------+\n",
      "|Workforce Planning|85090.82  |\n",
      "|Web Development   |84814.36  |\n",
      "|UX Design         |84821.2   |\n",
      "|UI Design         |85164.64  |\n",
      "|Treasury          |84783.27  |\n",
      "|Training          |85148.1   |\n",
      "|Tax               |85018.57  |\n",
      "|Sustainability    |85178.99  |\n",
      "|Supply Chain      |84952.89  |\n",
      "|Subscriptions     |84899.19  |\n",
      "+------------------+----------+\n",
      "\n",
      "Query (a) time: 11.36 seconds\n",
      "\n",
      "=== Query (b): Nested aggregation ===\n",
      "+------------+-----------------+\n",
      "|country     |avg_salary       |\n",
      "+------------+-----------------+\n",
      "|Egypt       |87382.22963311202|\n",
      "|Kuwait      |87349.3517377211 |\n",
      "|Saudi Arabia|87348.80512175431|\n",
      "|Panama      |87345.00623707911|\n",
      "|Denmark     |87328.03514120901|\n",
      "|Jamaica     |87305.43735208298|\n",
      "|Lebanon     |87292.76891750698|\n",
      "|Turkey      |87290.69043798618|\n",
      "|Malaysia    |87253.78746341488|\n",
      "|Kazakhstan  |87251.74274968785|\n",
      "+------------+-----------------+\n",
      "\n",
      "Query (b) time: 7.45 seconds\n",
      "\n",
      "=== Query (c): Top 10 salaries ===\n",
      "+------+----------+---------+------+----------------+------+------------+\n",
      "|id    |first_name|last_name|gender|department      |salary|country     |\n",
      "+------+----------+---------+------+----------------+------+------------+\n",
      "|764650|Tim       |Jensen   |Male  |Analytics       |160000|Bulgaria    |\n",
      "|10016 |Anastasia |Edwards  |Female|Analytics       |159998|Kuwait      |\n",
      "|754528|Adrian    |Young    |Male  |Game Analytics  |159997|UK          |\n",
      "|240511|Diego     |Lopez    |Male  |Game Analytics  |159995|Malaysia    |\n",
      "|893472|Mariana   |Cook     |Female|People Analytics|159995|South Africa|\n",
      "|359891|Mariana   |Novak    |Female|Game Analytics  |159992|Mexico      |\n",
      "|53102 |Felix     |Taylor   |Male  |Data Science    |159989|Bosnia      |\n",
      "|768143|Teresa    |Campbell |Female|Game Analytics  |159988|Spain       |\n",
      "|729165|Antonio   |Weber    |Male  |Analytics       |159987|Moldova     |\n",
      "|952549|Adrian    |Harris   |Male  |Analytics       |159986|Georgia     |\n",
      "+------+----------+---------+------+----------------+------+------------+\n",
      "\n",
      "Query (c) time: 7.56 seconds\n",
      "\n",
      "=== Query (d): Heavy self-join COUNT (DANGEROUS) ===\n",
      "Join count: 10983941260\n",
      "Query (d) time: 37.97 seconds\n",
      "\n",
      "=== Query (d-safe): Join-equivalent rewrite ===\n",
      "+-----------+\n",
      "|total_pairs|\n",
      "+-----------+\n",
      "|10983941260|\n",
      "+-----------+\n",
      "\n",
      "Query (d-safe) time: 3.25 seconds\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 0. Imports & Spark session\n",
    "# ============================================\n",
    "\n",
    "import time\n",
    "import builtins  # <-- IMPORTANT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    round as spark_round,   # Spark round ONLY for Columns\n",
    "    count,\n",
    "    col,\n",
    "    sum as _sum\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"PostgresVsSparkBenchmark\")\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.2\")\n",
    "    .config(\"spark.eventLog.enabled\", \"true\")\n",
    "    .config(\"spark.eventLog.dir\", \"/tmp/spark-events\")\n",
    "    .config(\"spark.history.fs.logDirectory\", \"/tmp/spark-events\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "    .config(\"spark.default.parallelism\", \"4\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# ============================================\n",
    "# 1. JDBC connection config\n",
    "# ============================================\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/postgres\"\n",
    "jdbc_props = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# 2. Load data from PostgreSQL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Loading people_big from PostgreSQL ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_big = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"people_big\",\n",
    "    properties=jdbc_props\n",
    ")\n",
    "\n",
    "# Force materialization\n",
    "row_count = df_big.count()\n",
    "\n",
    "print(f\"Rows loaded: {row_count}\")\n",
    "print(\"Load time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# Register temp view\n",
    "df_big.createOrReplaceTempView(\"people_big\")\n",
    "\n",
    "# ============================================\n",
    "# 3. Query (a): Simple aggregation\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (a): AVG salary per department ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_a = (\n",
    "    df_big\n",
    "    .groupBy(\"department\")\n",
    "    .agg(spark_round(avg(\"salary\"), 2).alias(\"avg_salary\"))\n",
    "    .orderBy(\"department\", ascending=False)\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "q_a.collect()\n",
    "q_a.show(truncate=False)\n",
    "print(\"Query (a) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 4. Query (b): Nested aggregation\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (b): Nested aggregation ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_b = spark.sql(\"\"\"\n",
    "SELECT country, AVG(avg_salary) AS avg_salary\n",
    "FROM (\n",
    "    SELECT country, department, AVG(salary) AS avg_salary\n",
    "    FROM people_big\n",
    "    GROUP BY country, department\n",
    ") sub\n",
    "GROUP BY country\n",
    "ORDER BY avg_salary DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "q_b.collect()\n",
    "q_b.show(truncate=False)\n",
    "print(\"Query (b) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 5. Query (c): Sorting + Top-N\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (c): Top 10 salaries ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_c = (\n",
    "    df_big\n",
    "    .orderBy(col(\"salary\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "q_c.collect()\n",
    "q_c.show(truncate=False)\n",
    "print(\"Query (c) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 6. Query (d): Heavy self-join (COUNT only)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (d): Heavy self-join COUNT (DANGEROUS) ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_d = (\n",
    "    df_big.alias(\"p1\")\n",
    "    .join(df_big.alias(\"p2\"), on=\"country\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "print(\"Join count:\", q_d)\n",
    "print(\"Query (d) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 7. Query (d-safe): Join-equivalent rewrite\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== Query (d-safe): Join-equivalent rewrite ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "grouped = df_big.groupBy(\"country\").agg(count(\"*\").alias(\"cnt\"))\n",
    "\n",
    "q_d_safe = grouped.select(\n",
    "    _sum(col(\"cnt\") * col(\"cnt\")).alias(\"total_pairs\")\n",
    ")\n",
    "\n",
    "q_d_safe.collect()\n",
    "q_d_safe.show()\n",
    "print(\"Query (d-safe) time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# ============================================\n",
    "# 8. Cleanup\n",
    "# ============================================\n",
    "\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a295618",
   "metadata": {},
   "source": [
    "## Exercise 4: Port the SQL queries from exercise 1 to spark\n",
    "Exercise 1 - PostgreSQL Analytical Queries (E-commerce)\n",
    "- A. What is the single item with the highest price_per_unit?  \n",
    "- B. What are the top 3 products with the highest total quantity sold across all orders?  \n",
    "- C. What is the total revenue per product category?  \n",
    "  (Revenue = price_per_unit Ã— quantity)\n",
    "- D. Which customers have the highest total spending?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706d6ae2-b3bf-4dc2-a270-4a6fdc4c1887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+--------+--------------+----------+-------+\n",
      "|customer_name|product_category|quantity|price_per_unit|order_date|country|\n",
      "+-------------+----------------+--------+--------------+----------+-------+\n",
      "|   Emma Brown|      Automotive|       3|       2000.00|2024-10-11|  Italy|\n",
      "+-------------+----------------+--------+--------------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the orders table from PostgreSQL\n",
    "df_orders = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"orders\",\n",
    "    properties=jdbc_props\n",
    ")\n",
    "\n",
    "df_orders.createOrReplaceTempView(\"orders\")\n",
    "\n",
    "#A. Single item with highest price_per_unit\n",
    "q_A = df_orders.orderBy(col(\"price_per_unit\").desc()).limit(1)\n",
    "q_A.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e745c6a-6830-4458-b82c-967e6c456d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+\n",
      "|product_category|total_quantity_sold|\n",
      "+----------------+-------------------+\n",
      "| Health & Beauty|             300842|\n",
      "|     Electronics|             300804|\n",
      "|            Toys|             300598|\n",
      "+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#B. Top 3 products with highest total quantity sold\n",
    "q_B = (\n",
    "    df_orders\n",
    "    .groupBy(\"product_category\")\n",
    "    .agg(_sum(\"quantity\").alias(\"total_quantity_sold\"))\n",
    "    .orderBy(col(\"total_quantity_sold\").desc())\n",
    "    .limit(3)\n",
    ")\n",
    "q_B.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aeef017-5b69-4b4c-887e-4e1fe95ac4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|product_category|total_revenue|\n",
      "+----------------+-------------+\n",
      "|      Automotive| 306589798.86|\n",
      "|     Electronics| 241525009.45|\n",
      "|   Home & Garden|  78023780.09|\n",
      "|          Sports|  61848990.83|\n",
      "| Health & Beauty|  46599817.89|\n",
      "| Office Supplies|  38276061.64|\n",
      "|         Fashion|  31566368.22|\n",
      "|            Toys|  23271039.02|\n",
      "|         Grocery|  15268355.66|\n",
      "|           Books|  12731976.04|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#C. Total revenue per product category\n",
    "q_C = (\n",
    "    df_orders\n",
    "    .groupBy(\"product_category\")\n",
    "    .agg(_sum(col(\"price_per_unit\") * col(\"quantity\")).alias(\"total_revenue\"))\n",
    "    .orderBy(col(\"total_revenue\").desc())\n",
    ")\n",
    "q_C.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a84c71d2-7109-4815-8d6c-aab9a7fe4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "| customer_name|total_spent|\n",
      "+--------------+-----------+\n",
      "|  Carol Taylor|  991179.18|\n",
      "|    Nina Lopez|  975444.95|\n",
      "|Daniel Jackson|  959344.48|\n",
      "|   Carol Lewis|  947708.57|\n",
      "|  Daniel Young|  946030.14|\n",
      "|Alice Martinez|  935100.02|\n",
      "|   Ethan Perez|  934841.24|\n",
      "|       Leo Lee|  934796.48|\n",
      "|     Eve Young|  933176.86|\n",
      "| Ivy Rodriguez|  925742.64|\n",
      "| Nina Robinson|  923627.53|\n",
      "|   John Thomas|  922858.59|\n",
      "|    Eve Taylor|  917620.11|\n",
      "|   Henry Smith|  916273.48|\n",
      "|    Mia Wilson|  914740.05|\n",
      "|  Liam Johnson|  914266.79|\n",
      "|   Alice Brown|  913262.30|\n",
      "|    Bob Walker|  913202.74|\n",
      "|Olivia Sanchez|  912017.65|\n",
      "|  Amelia Moore|  911627.44|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#D. Customers with highest total spending\n",
    "q_D = (\n",
    "    df_orders\n",
    "    .groupBy(\"customer_name\")\n",
    "    .agg(_sum(col(\"price_per_unit\") * col(\"quantity\")).alias(\"total_spent\"))\n",
    "    .orderBy(col(\"total_spent\").desc())\n",
    "    .limit(20)\n",
    ")\n",
    "q_D.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f41a5c-7a18-42b5-a9fb-8b52af4d16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Final Step: Cleanup\n",
    "# ============================================\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
